Read and make notes for [MAML B paper]([https://arxiv.org/pdf/1801.08930.pdf](https://arxiv.org/pdf/1801.08930.pdf))
Fix up Q learning code (shapes)
- make plots: 
	- Starting config
		- Start with alphaW = 0
		- set latent to equal number states
		- if you set W to be identity matrix, lr = 0, then we expect just regular Q learning
	- Plot the correct q value action per cue, we should see it converge to either 1 or 0
	- Implement block 2 experiment, see if we can do rapid learning



$$L(θ) = \frac{1}{J} \sum_{j=1}^{J} \frac{1}{M} \sum_{m=N+1}^{N+M} -\log p(x_{jm} | \phi_j)$$ 

-  average over J tasks. The algorithm is trying to find parameters θ that work well across many tasks, not just one, so it averages the performance across all tasks.

- $\frac{1}{M} \sum_{m=N+1}^{N+M}$ average over M samples from a task-specific dataset. These samples are used to evaluate how well the model performs after being fine-tuned to a specific task.

-  $-\log p(x_{jm} | \phi_j)$ \) negative log-likelihood of the model's predictions on the task-specific data \( $x_{jm}$ \) given the task-specific parameters \( $\phi_j$ \). The log-likelihood measures how probable the observed data is, given the model parameters. A higher likelihood (so lower negative log-likelihood) means the model's parameters are more likely to have generated the observed data.

$$\phi_j = \theta - \alpha \nabla_\theta \frac{1}{N} \sum_{n=1}^{N} -\log p(x_{jn} | \theta)$$ 

  - \( $\theta$ \): shared initial parameters before adaptation.
  
  - \( $\alpha$\): meta-learning rate. 
  
  - \( $\nabla_\theta$ \): gradient with respect to the parameters θ.
  
  - $$\frac{1}{N} \sum_{n=1}^{N} -\log p(x_{jn} | \theta)$$:  average negative log-likelihood over N samples from the same task before adaptation. It measures how well the model with parameters θ predicts the task-specific data.
